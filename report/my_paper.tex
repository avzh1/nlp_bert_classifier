%
% File acl2019.tex
%
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage{acl2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}

\usepackage{url}

% \aclfinalcopy % Uncomment this line for the final submission
% \def\aclpaperid{***} %  Enter the acl Paper ID here

\setlength\titlebox{4cm}  
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\title{Imperial College: `Don't Patronize Me!' Coursework 2024}

\author{Anton Zhitomirsky \\
  Imperial College London \\
  \texttt{az620@ic.ac.uk}
}

\begin{document}
\maketitle

\section{Introduction}

% \textbf{5 marks}: Introduction, with an explanation of the task and the
% dataset. You may want to read/cite the task paper (and any other paper of
% your choosing).

Most social media websites contain portals through which even unregistered users can view their content. Focusing primarily on textual posts, this leaves many vulnerable users to unfiltered content, which may be harmful if not regulated. \citet{Ng-discrimination} concludes that regardless of intention, if this content goes unfiltered it may ``justify'', ``encode'', ``enact'' and ``routinize'' discrimination amongst targeted groups.

This motivates the creation and popularization of The Don't Patronize Me! dataset to provide a source for engineers to develop categorization algorithms to progress the protection of targeted groups. The dataset, authored by \citet{perez-almendros-etal-2020-dont}, is a labelled dataset containing more than 10,000 paragraphs extracted from news stories, country of origin, and keyword which is then labelled indicating its level of Patronizing and Condescending Language (PCL).

I propose an extension to the base-line categorization model `\texttt{RoBERTa}' which beats the initial benchmarks of \texttt{0.48} F1-score on the dev-set and \texttt{0.49} on the test-set.

\begin{table}[!h]
    \centering
    \begin{tabular}{ |l||c|c|  }
        \hline
        Model              & F1 dev-set & F1 val-set \\
        \hline
        Mine               & ?          & ?          \\
        \hline
    \end{tabular}
    \caption{F1 score of models attempted}    
\end{table}

\section{Data Analysis}

% \emph{For a written description of the training data. This should include}

% \begin{enumerate}
%     \item \textbf{5 marks}: Analysis of the class labels: how frequent these are and how they correlate with any feature of the data, e.g. input length.
%     \item \textbf{10 marks}: Qualitative assessment of the dataset, considering either how hard or how subjective the task is, providing examples in your report.
% \end{enumerate}

\subsection{Feature Distribution}\label{sect:feature-distribution}

Labels arrive annotated by two main annotators. Their values span from $[0,4]$ indicating the level of PCL within the text snippet. \citet{perez-almendros-etal-2020-dont} explains how both annotators individually classify each sentence with a score in the range $[0,2]$ to indicate the strength of PCL from: no PCL, borderline PCL and blatant PCL. These scores were then summed to produce a 5-point scale of PCL, where the range $[0,1]$ indicates a negative example, and $[2,4]$ indicating a positive example.

Data also arrives with labeled country information indicating the source media outlet, and a keyword field. The keyword is provided as input to the model as the search term used to retrieve texts about a target community.

\subsection{Data Distribution}

% The data arrives labeled with a balanced distribution between countries and keyword.

\begin{figure}[!h]
    \centering
    \includegraphics[trim=0cm 0cm 0cm .8cm, clip, width=\linewidth]{figures/text-input-length-by-binary-patronizing.png}
    \caption{Histogram of word count by PCL (true) and non PCL (false)\footnotemark}
    \label{fig:word-count}
\end{figure}

\footnotetext{Without loss of generality, text with more than 250 words have been clipped}

The test data contains a disproportionate number of negative (9475) and positive (993) examples of PCL. Furthermore, the distribution of word counts between the two (See Figure~\ref{fig:word-count}) offers no obvious underlying pattern between the two classes. This is because natural language is about how words are said, instead of the quantity. 

\subsection{Subjective Difficulty}

Indeed, \citet{perez-almendros-etal-2020-dont} mention the subjective nature of the task as it is very subjective. The word `lovely' appears uniquely in PCL text examples. This word isn't negative, but in the context of the sentence (par\_id: 2404) ``We think it's lovely that so many have come forward to help out a family clearly in need!'' the sentence has been labeled as blatantly PCL with a score of 3. In-fact, tweaking the sentence from ``a family clearly in need'' to ``families in need'' removes entitlement and converts it to compassion.

\subsection{Artifacts}\label{sect:artifacts}

The flexible environment of news articles allows for authors to post resources and further reading, like in the case of par\_id: 2838: \emph{``Read more about the site's history here: [LINK]''}. Therefore, with a primitive language processing model, we cannot determine the degree of PCL from a link. Some links and references are also clipped in the source with token ``TOOLONG'' which also aught to be pre-processed to avoid confusion from the model. Additionally, writers are free to reference other users (par\_id: 5598 ``@toekunbore [...]''), the handle of which would likely be ignored by language models.

Lastly, adding to the complexity of processing language, we must also filter and process out-of-vocabulary words. This may appear in the form of a typo like in par\_id: 8221 \emph{``Do they think it is "" \textbf{jsutice} "" \textbf{ti} imprison [...]''}, hyperboles like par\_id: 5333 \emph{``But \textbf{nooooo} [...]''}, or slang like in par\_id: 1674 \emph{``Kyle really your a pig, \textbf{lol} [...]''}.

\section{Input strategy}

% \textbf{10 marks}: Further model improvements (beyond using a bigger transformer model), for example pre-processing, data sampling, data augmentation, ensembling, etc. Two main improvements, with a third less explored improvement is sufficient. For example: try several different data sampling approaches, try several data augmentation strategies by perturbing observations in different ways, and then see if incorporating one of the categorical columns improves performance.

% \begin{itemize}
%     \item try and balance out the classes by applying synonyms to low frequency labels
%     \item data-sampling, research: is it common to feed in an equal proportion of each class in batches during training?
%     \item using country code also
% \end{itemize}

The data is very imbalanced; Section~\ref{sect:feature-distribution} discusses the sparsity of positive PCL examples in the training data. This less-so because of poor sampling, but rather reflecting the distribution of PCL in media. Therefore, it is possible that the model may experience great performance in the majority negative class, and fail to learn details about the minority positive class (\citet{alberto-imbalanced-datasets}). We therefore propose a few methods to increase the amount of training data available to the model (Section~\ref{sect:model}).

\subsection{Pre-processing}

We can synthetically produce more data points for the minority positive class by changing the content of the sample without changing the sentiment of the text. 

\subsubsection{Spelling Mistakes}

Section~\ref{sect:artifacts} describes artifacts in the training data that may be problematic in their small quantities. However, we may switch the ordering of letters within words to purposefully mimic grammatical mistakes. Not only will this provide for potentially more data, it also trains the network to be more resilient to spelling mistakes which is an important edge case for models to handle. 

\subsubsection{Synonym insertion}

% https://towardsdatascience.com/data-preprocessing-in-nlp-c371d53ba3e0

Another technique for synthetically increasing the number of positive examples is to replace some words with synonyms without changing a sentence's sentiment. For this, we have to have enough synonym variety whilst minimizing the cosine distance between the two swapped words. The hope is to form legitimate sentences with equal PCL scores.

\subsubsection{Masking inputs}

Finally, an experiment surrounding masking entries in sentences is a potential useful augmentation that may increase the pool of available positive samples. This may help with boundary cases of PCL, as often a few words changed may increase the degree of PCL. Therefore, by masking there is a high chance that irrelevant filler words may be covered which will force more attention on more significant vocabulary. 

\subsection{Data Sampling}

With the above synthetic augmentations to data, we should obtain enough data to evenly batch training with even quantities of negative and positive examples, thus solving the data imbalance issue and allowing for a more balanced F-1 score.

\section{Modelling}\label{sect:model}

\emph{For the successful implementation of a classifier model (this could be a transformer or any other ML model of your choice. Do give justification for your choice.):}

\subsection{Model Choice}

\textbf{10 marks}: Successful implementation of a model (train and produce predictions which outperform the F1 score for the RoBERTa-base baseline provided). 7 marks for outperforming the baseline model on the official dev set (0.48) and 3 marks for outperforming the baseline model on the test set (0.49).

\subsection{Hyper-parameters}

\textbf{5 marks}: Choice of model hyper-parameters and description of your model setup. This should include choosing an appropriate learning rate and checking whether implementing a learning schedule improves performance. Also consider whether your model is cased or uncased. You should mention how many epochs you train the model for, whether you are using any early-stopping, and how you are using the training labels.

\section{Results}

\textbf{5 marks}: Description of the model results and your hyper-parameter tuning (some evidence of this is required in your report). Your results should show how the different strategies you have tried impacted the model performance. For any results presented in your paper, you should be clear if these are from your own internal dev set or the official dev set.

\subsection{Comparison}

\textbf{10 marks}: Compare your model performance to two simple baselines (e.g. a BoW model). Share some of the features that one of your baseline models used, and highlight an example misclassified with a suggestion of why the baseline may have made the misclassification.

\section{Analysis}

\emph{Analysis questions to be answered (these questions can be answered without training any additional models): Your report should state the analysis questions so that this can be read as a self-contained report, rather than referring to ‘analysis question 1’ etc.}

\begin{enumerate}
    \item \textbf{5 marks}: To what extent is the model better at predicting examples with a higher level of patronising content? Justify your answer.
    \item \textbf{5 marks}: How does the length of the input sequence impact the model performance? If there is any difference, speculate why.
    \item \textbf{5 marks}: To what extent does model performance depend on the data categories? E.g. Observations for homeless vs poor-families, etc.
\end{enumerate}

\section{Conclusion}

\textbf{5 marks}: Conclusion, with a summary of your results, and your key
findings from the analysis questions. You should suggest at least one further
experiment as a next step.

\bibliography{references}
\bibliographystyle{acl_natbib}

\end{document}
