{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of the \"Don't Patronize Me!\" Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Binary Classification to predict whether a text contains patronizing and condescending language. The task was task 4 (subtask 1) in the SemEval 2022 competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avzh1/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "from nltk import PorterStemmer, WordNetLemmatizer\n",
    "import codecs\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "# Pre-trained models\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs, MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "\n",
    "def fix_seed(seed=420.69):\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "#   np.random.seed(seed)\n",
    "#   random.seed(seed)\n",
    "\n",
    "fix_seed()\n",
    "\n",
    "data_path = '../bin/data'\n",
    "embeddings_path = '../bin/word_embeddings'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "  DEVICE = 'cpu'\n",
    "else:\n",
    "  DEVICE = 'cuda:0'\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_params = {\n",
    "    'model': 'None'\n",
    "    , 'batch_size': 5\n",
    "    , 'embedding_dimensions': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading\n",
    "\n",
    "Load the data into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "train_data_path = f'{data_path}/dontpatronizeme_pcl.tsv'\n",
    "test_data_path  = f'{data_path}/task4_test.tsv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_path, delimiter='\\t', skiprows=4, header=None, names=['par_id','art_id','keyword','country_code', 'text','label'])\n",
    "test_data  = pd.read_csv(test_data_path,  delimiter='\\t', skiprows=4, header=None, names=['par_id','art_id','keyword','country_code', 'text'])\n",
    "\n",
    "train_data = train_data.drop(['art_id'], axis=1)\n",
    "test_data = test_data.drop(['art_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate label information to train data\n",
    "dev_label_path   = f'{data_path}/dev_semeval_parids-labels.csv'\n",
    "train_label_path = f'{data_path}/train_semeval_parids-labels.csv'\n",
    "\n",
    "dev_label   = pd.read_csv(dev_label_path, delimiter=',')\n",
    "train_label = pd.read_csv(train_label_path, delimiter=',')\n",
    "\n",
    "detailed_labels = pd.concat([dev_label, train_label], ignore_index=True, join='inner', names=['simple', 'detailed'])\n",
    "train_data = pd.merge(train_data, detailed_labels, on='par_id')\n",
    "train_data = train_data.rename(columns={'label_x': 'label', 'label_y': 'label_detailed'})\n",
    "\n",
    "train_data = train_data.drop('par_id', axis=1)\n",
    "test_data = test_data.drop('par_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Binary Classification column for ease of checking\n",
    "train_data.loc[:, 'is_patronizing'] = 0\n",
    "train_data.loc[train_data['label'].isin([2,3,4]), 'is_patronizing'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(subset = 'text')\n",
    "test_data = test_data.dropna(subset = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_set = sorted(set(train_data['keyword']))\n",
    "country_set = sorted(set(train_data['country_code']))\n",
    "\n",
    "def keyword_to_id(country:str, keyword_set=keyword_set):\n",
    "    return keyword_set.index(country)\n",
    "\n",
    "def id_to_keyword(id:int, keyword_set=keyword_set):\n",
    "    assert id >= 0\n",
    "    assert id < len(keyword_set)\n",
    "    return keyword_set[id]\n",
    "\n",
    "def country_to_id(country:str, country_set=country_set):\n",
    "    return country_set.index(country)\n",
    "\n",
    "def id_to_country(id:int, country_set=country_set):\n",
    "    assert id >= 0\n",
    "    assert id < len(country_set)\n",
    "    return country_set[id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splits\n",
    "\n",
    "split the data whilst keeping distributions of country, text and is_patronizing counts even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8374, 3)\n",
      "y_train shape: (8374,)\n",
      "X_test shape : (2094, 3)\n",
      "y_test shape : (2094,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data[['text', 'keyword', 'country_code']]\n",
    "y = train_data['is_patronizing']\n",
    "\n",
    "# The stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify. \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0, stratify=train_data[['is_patronizing']])\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape : {X_val.shape}\")\n",
    "print(f\"y_test shape : {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_patronizing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting histogram\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_patronizing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_patronizing\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Adding labels and title\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/pandas/core/series.py:2238\u001b[0m, in \u001b[0;36mSeries.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index=False only valid with DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2236\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 2238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_patronizing'"
     ]
    }
   ],
   "source": [
    "# Plotting histogram\n",
    "y_train.groupby(by='is_patronizing')['is_patronizing'].count().plot(kind='bar')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Label Frequencies')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelledDataset(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame):\n",
    "        self.data = data_frame\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns a singular item with all pre-processing required for the tester\"\"\"\n",
    "\n",
    "        data = {'keyword'     : self.data['keyword'].iloc[idx],\n",
    "                'country_code': self.data['country_code'].iloc[idx],\n",
    "                'text'        : self.data['text'].iloc[idx]}\n",
    "        \n",
    "        # instead of label and label_detailed we use is_patronizing\n",
    "        label = {'is_patronizing': self.data['is_patronizing'].iloc[idx]}\n",
    "\n",
    "        return data, label\n",
    "    \n",
    "class WithheldDataset(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame):\n",
    "        self.data = data_frame\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = {'keyword'     : self.data['keyword'].iloc[idx],\n",
    "                'country_code': self.data['country_code'].iloc[idx],\n",
    "                'text'        : self.data['text'].iloc[idx]}\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atm, collate_fn is shared between the two functions, therefore, we keep it separate and feed it as input to both functions when we define the DataLoader\n",
    "def collate_fn(batch, tokenizer, trunc_len = 300):\n",
    "    \"\"\"merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style\"\"\"\n",
    "\n",
    "    encodings = []\n",
    "\n",
    "    # 1. We pad shorter sentences to a length of trunc_len tokens since the maximum sequence size for BERT is 512\n",
    "    batched_text = [item['text'] for item in batch]\n",
    "    encodings    = tokenizer(batched_text, return_tensors='pt', padding=True, truncation=True, max_length=trunc_len)\n",
    "\n",
    "    # 2. We encode the keywords in the sorted order that they appear in the text. We know the set of words from the pre-requisites.\n",
    "    batched_keywords = list(map(lambda item: keyword_to_id(item['keyword']), batch))\n",
    "    encodings['keywords'] =  torch.tensor(batched_keywords)\n",
    "\n",
    "    # 3. We similarly do the above for the countries to get an index encoding of the country\n",
    "    batched_country_codes = list(map(lambda item: country_to_id(item['country_code']), batch))\n",
    "    encodings['country_code'] =  torch.tensor(batched_country_codes)\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# we can check the parameters of this tokenizer\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_collate = partial(collate_fn, tokenizer=tokenizer)\n",
    "\n",
    "sampled_train_data = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "sampled_val_data = pd.merge(X_val, y_val, left_index=True, right_index=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=WithheldDataset(sampled_train_data), batch_size=h_params['batch_size'], shuffle=True, collate_fn=partial_collate)\n",
    "\n",
    "val_loader = DataLoader(dataset=WithheldDataset(sampled_val_data), batch_size=h_params['batch_size'], shuffle=True, collate_fn=partial_collate)\n",
    "\n",
    "train_loader = DataLoader(dataset=LabelledDataset(train_data), batch_size=h_params['batch_size'], shuffle=True, collate_fn=partial_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids, [[101, 107, 23750, 7236, 1116, 1105, 1110, 1304, 12647, 1874, 6052, 3946, 1104, 1103, 1277, 1834, 1619, 1134, 2502, 1120, 170, 1159, 1165, 1103, 2332, 11040, 1105, 2993, 1104, 1142, 8018, 1416, 1110, 2898, 117, 1105, 1103, 1223, 14703, 21160, 2332, 4291, 1110, 7851, 1106, 16974, 6818, 1826, 117, 107, 1987, 25503, 1163, 119, 102], [101, 107, 5472, 1168, 18085, 117, 1412, 1826, 1105, 5052, 2988, 17030, 3171, 1107, 3309, 11549, 1651, 1272, 1152, 1132, 1621, 1103, 1211, 8018, 1106, 1136, 3146, 1147, 2527, 107, 117, 24446, 2225, 3416, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1109, 3819, 1110, 1103, 2904, 1871, 1104, 170, 2793, 8672, 5455, 1113, 5696, 7162, 1107, 26057, 14824, 18255, 2180, 1574, 1115, 1486, 1120, 1655, 1479, 22336, 1116, 3950, 1111, 1690, 19241, 1107, 10605, 12489, 2572, 117, 1103, 26057, 14824, 18255, 2180, 1574, 3834, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1109, 5888, 112, 1160, 118, 1159, 1398, 118, 2537, 1248, 19670, 1189, 1117, 1963, 1107, 2057, 1133, 1225, 183, 112, 189, 1138, 170, 2640, 119, 1124, 1125, 1151, 1113, 1103, 10302, 2190, 1290, 16892, 119, 127, 1114, 170, 5871, 4206, 28108, 3773, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1109, 2415, 1144, 1185, 2332, 6245, 1111, 2636, 1105, 1535, 117, 1867, 1103, 23750, 117, 5321, 1122, 1169, 2612, 1263, 118, 1858, 2952, 1105, 9189, 7031, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "token_type_ids, [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "attention_mask, [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "keywords, [8, 8, 3, 0, 9]\n",
      "country_code, [1, 14, 17, 14, 10]\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "  # Print the labels we received\n",
    "  for key, value in batch.items():\n",
    "    print(f'{key}, {value.numpy().tolist()}')\n",
    "  \n",
    "  # Don't print for the other batches... (we get the idea)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_hate_speech(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        # BERT Model\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        # Task A\n",
    "        self.projection_a = torch.nn.Sequential(torch.nn.Dropout(0.2),\n",
    "                                                torch.nn.Linear(config.hidden_size, 2))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # Logits A\n",
    "        logits_a = self.projection_a(outputs[1])\n",
    "\n",
    "        return logits_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_hate_speech():\n",
    "\n",
    "    #call our custom BERT model and pass as parameter the name of an available pretrained model\n",
    "    model = BERT_hate_speech.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./experiment/hate_speech',\n",
    "        learning_rate = 0.0001,\n",
    "        logging_steps= 100,\n",
    "        per_device_train_batch_size=32,\n",
    "        num_train_epochs = 3,\n",
    "        remove_unused_columns=False # This argument prevents the collator to drop data from our batch when customizing the data collator\n",
    "    )\n",
    "    trainer = Trainer_hate_speech(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=sampled_train_data\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model('./models/ht_bert_finetuned/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BERT_hate_speech were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['projection_a.1.bias', 'projection_a.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain_hate_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m, in \u001b[0;36mmain_hate_speech\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain_hate_speech\u001b[39m():\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#call our custom BERT model and pass as parameter the name of an available pretrained model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m BERT_hate_speech\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./experiment/hate_speech\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# This argument prevents the collator to drop data from our batch when customizing the data collator\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m Trainer_hate_speech(\n\u001b[1;32m     15\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m         args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     17\u001b[0m         train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     18\u001b[0m         data_collator\u001b[38;5;241m=\u001b[39mtrain_dataset\u001b[38;5;241m.\u001b[39mcollate_fn,\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m<string>:123\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/transformers/training_args.py:1528\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1533\u001b[0m ):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1536\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1537\u001b[0m     )\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1549\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/transformers/training_args.py:1995\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1994\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:56\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     54\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/Documents/imperial/year4/lectures/nlp/Coursework/nlp/.venv/lib/python3.10/site-packages/transformers/training_args.py:1905\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   1904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 1905\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1906\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1907\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1908\u001b[0m         )\n\u001b[1;32m   1909\u001b[0m     AcceleratorState\u001b[38;5;241m.\u001b[39m_reset_state(reset_partial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "main_hate_speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Not Patronizing'), Text(0, 1.5, 'Patronizing')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set(y_pred)\n",
    "cm = confusion_matrix(y_val, y_pred, labels=[0, 1]) \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap=sns.color_palette(\"ch:s=-.2,r=.6\", as_cmap=True));  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['Not Patronizing', 'Patronizing'])\n",
    "ax.yaxis.set_ticklabels(['Not Patronizing', 'Patronizing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1890\n",
      "           1       0.56      0.34      0.43       204\n",
      "\n",
      "    accuracy                           0.91      2094\n",
      "   macro avg       0.75      0.66      0.69      2094\n",
      "weighted avg       0.90      0.91      0.90      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 163.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Paragraph example ===\n",
      "The common thieves then stole a crust of bread , the law came down upon the hungry heads ; the haughty land robber stole land with men resources and all contents . the first they said were a hopeless conviction . while they escaped the law by trick ; that grave , one-sided justice would not do -- the poor call for consideration , too . the cruel people started the unholy war , then from the line of action they kept far ; they pushed to the front sons of the poor , there to do battle , die , suffer galore , as the guns raged , liberty loans they raised , and in glorious tones , we sung freedom 's praise . those who made wars should first went to the front , and of shot and shell bear there the brunt : in first lines of action they were all due , if to their country and people they were true : when this was demanded in right of all , there would have been no more deadly cannon balls : the downtrodden poor people of us joined together and prevented the pakistani rulers our rights to purloin .\n",
      "\tReal Label:      1\n",
      "\tModel Prediction:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get one random sample from the test data\n",
    "random_index = X_val.sample(n=1).index.values[0]\n",
    "\n",
    "while random_index not in train_data.index:\n",
    "    random_index = X_val.sample(n=1).index.values[0]\n",
    "\n",
    "# Extract random sample\n",
    "tdf = train_data.loc[[random_index]][['text', 'is_patronizing']]\n",
    "test_paragraph, real_label = tdf['text'].values[0], tdf['is_patronizing'].values[0]\n",
    "\n",
    "# Get model prediction\n",
    "predicted_label, raw_outputs = task1_model.predict([tdf['text'].values[0]])\n",
    "# predicted_label = task1_model.predict(tdf['text'].values[0])\n",
    "\n",
    "print(f\"=== Paragraph example ===\\n{test_paragraph.capitalize()}\")\n",
    "print(f\"\\tReal Label:      {real_label}\")\n",
    "print(f\"\\tModel Prediction:{predicted_label[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:05<00:00,  7.29it/s]\n",
      "100%|██████████| 105/105 [00:14<00:00,  7.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_and_save_predictions(dataset, save_name, model=task1_model):\n",
    "    y_pred, _ = model.predict(dataset.tolist())\n",
    "    np.savetxt(f'{save_name}.txt', y_pred, fmt='%d')\n",
    "\n",
    "# train predictions\n",
    "get_and_save_predictions(test_data['text'], \"test\")\n",
    "\n",
    "# test predictions\n",
    "get_and_save_predictions(train_data['text'], \"dev\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
